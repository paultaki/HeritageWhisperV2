HeritageWhisper AI Prompt Generation System
Technical Specification v1.2 - Production Ready
Last Updated: October 5, 2025 Owner: Paul Takisaki Purpose: Complete implementation guide for AI-powered memory prompt system Status: Ready for Development

TABLE OF CONTENTS
	1	Product Context & Business Goals
	2	System Architecture Overview
	3	User Flows
	4	Database Schema
	5	API Specifications
	6	AI Prompt Templates
	7	Business Logic & Algorithms
	8	Edge Cases & Fallbacks
	9	Safety & Compliance
	10	Metrics & Success Criteria
	11	Cost Model & Budget
	12	Implementation Checklist

1. PRODUCT CONTEXT & BUSINESS GOALS
1.1 The Problem
Seniors struggle to remember what stories to tell. Generic prompts like "Tell me about your wedding" fail to trigger forgotten memories.
1.2 The Solution
AI analyzes their existing stories to generate personalized prompts that trigger specific, forgotten memories. Each prompt references something they already shared, making it feel like someone is genuinely listening.
1.3 The Differentiation
	•	StoryWorth: Generic list of 500 prompts (same for everyone)
	•	HeritageWhisper: "You mentioned your father's workshop in 1955. Who else spent time there with you?"
1.4 Business Objectives
Free Tier (Stories 1-3):
	•	Goal: Convert trial users to paid subscribers
	•	Strategy: Show AI "magic" at Stories 1, 2, and 3
	•	Target: 45% trial-to-paid conversion (baseline: 35-40%)
Paid Tier (Stories 4+):
	•	Goal: Retain subscribers for 12+ months
	•	Strategy: Maintain prompt quality through Story 20, then taper
	•	Target: 80% annual retention
Revenue Impact:
	•	Baseline: 1,000 paid users × $149 = $149,000/year
	•	5% conversion lift: +345 users × $149 = +$51,405/year
	•	AI cost: $1,757/year
	•	Net gain: $49,648/year (ROI: 28x)

2. SYSTEM ARCHITECTURE OVERVIEW
2.1 Three-Tier Prompt System


┌─────────────────────────────────────────────────────────┐
│                    TIER 1: TEMPLATES                     │
│  • Trigger: After every story save (synchronous)        │
│  • Method: Regex keyword extraction + template match    │
│  • Cost: $0 (no API call)                               │
│  • Expiry: 7 days                                       │
│  • Coverage: 60-70% of stories                          │
└─────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│                 TIER 2: ON-DEMAND AI                     │
│  • Trigger: When active_prompts is empty                │
│  • Method: GPT-4o analyzes last 3-5 stories             │
│  • Cost: ~$0.05 per generation                          │
│  • Expiry: 14 days                                      │
│  • Frequency: 2-3x per month per user                   │
└─────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│              TIER 3: MILESTONE ANALYSIS                  │
│  • Trigger: At stories 1,2,3,4,7,10,15,20,30,50,100     │
│  • Method: GPT-4o analyzes ALL stories for patterns     │
│  • Cost: $0.006 - $0.13 per analysis                    │
│  • Expiry: 30 days (60 days for premium seed)           │
│  • Generates: 1-3 high-quality prompts                  │
└─────────────────────────────────────────────────────────┘
2.2 Generate-and-Filter Flow


Story Save Event
      ↓
Tier 1: Generate 1 template prompt immediately
      ↓
Tier 3: Check if milestone (1,2,3,4,7,10,15,20,30,50,100)
      ↓
      YES → GPT-4o Analysis
            ↓
            Generate 3-5 candidate prompts
            ↓
            GPT-4o scores each (0-100)
            ↓
            Filter: Keep only score ≥ 50
            ↓
            Store top 1-3 in active_prompts
            ↓
            Mark with is_locked = true if Story 3 (for premium seed)
      ↓
      NO → Continue
      ↓
User Opens Timeline
      ↓
Call: GET /api/prompts/next
      ↓
Check: active_prompts (unexpired, not locked)
      ↓
      FOUND → Return prompt, increment shown_count
      ↓
      EMPTY → Check Tier 2 rate limit
              ↓
              OK → Generate Tier 2 prompt
              ↓
              RATE LIMITED → Return decade fallback
2.3 Key Design Principles
	1	Generate More, Show Less: Always generate 3-5 candidates, show top 1-2
	2	Deduplication: anchor_hash prevents semantic duplicates
	3	Safety First: do_not_ask + content classifier before insertion
	4	Graceful Degradation: Circuit breaker → decade fallback
	5	Cost Efficiency: Templates first (free), AI only when needed

3. USER FLOWS
3.1 Free Tier Flow (Stories 1-3)


┌──────────────────────────────────────────────────────────────┐
│                       STORY 1 FLOW                            │
└──────────────────────────────────────────────────────────────┘

User registers → Onboarding (birth year) → Timeline (empty)
                                              ↓
                                    Ghost prompts appear
                                    "1955 - The Year I Was Born"
                                              ↓
                                    User taps prompt → Records Story 1
                                              ↓
                         POST /api/stories (story 1 data)
                                              ↓
                              ┌───────────────┴───────────────┐
                              ↓                               ↓
                    Save to database              Tier 1: Extract keywords
                    Set free_stories_used = 1      Generate 1 template prompt
                              ↓                     (expires in 7 days)
                    Tier 3: Story 1 Milestone                ↓
                    GPT-4o generates 5 candidates   Store in active_prompts
                    Score and filter (≥50)
                    Store top 2
                              ↓
                    Return success to client
                              ↓
                    User sees timeline with Story 1 card
                              ↓
                    "Next Story" card appears:
                    "What happened the morning after you told
                     your father you were quitting?"
                    📍 Based on your 1955 story
                              ↓
                    [Record This Story 🎤] [Skip]

┌──────────────────────────────────────────────────────────────┐
│                       STORY 2 FLOW                            │
└──────────────────────────────────────────────────────────────┘

User taps "Record This Story" → Records Story 2
                                              ↓
                         POST /api/stories (story 2 data)
                                              ↓
                    Save to database
                    Set free_stories_used = 2
                    Mark previous prompt as used
                              ↓
                    Tier 1: Generate 1 template
                              ↓
                    Tier 3: Story 2 Milestone
                    GPT-4o analyzes both stories
                    Generates 4 candidates (2 expansion, 2 connection)
                    Score and filter
                    Store top 2
                              ↓
                    User sees "Next Story" card:
                    "Your father appears in both stories.
                     What's your earliest memory of him?"
                    📍 Connecting 1955 and 1982

┌──────────────────────────────────────────────────────────────┐
│                   STORY 3 + PAYWALL FLOW                      │
└──────────────────────────────────────────────────────────────┘

User records Story 3
                              ↓
                    POST /api/stories (story 3 data)
                              ↓
                    Save to database
                    Set free_stories_used = 3
                              ↓
                    Tier 1: Generate 1 template
                              ↓
                    Tier 3: Story 3 Milestone (SPECIAL)
                    GPT-4o analyzes all 3 stories
                    Generates 5 candidates
                    Score and filter
                              ↓
                    Store candidate #1 (highest score):
                      - is_locked = false (show immediately)
                      - expires_at = NOW() + 30 days
                              ↓
                    Store candidates #2-4 (premium seed):
                      - is_locked = true (hidden until payment)
                      - expires_at = NULL (unlocked on payment)
                              ↓
                    Return success
                              ↓
╔══════════════════════════════════════════════════════════════╗
║              PAYWALL CARD APPEARS                             ║
║                                                               ║
║  ✨ YOUR STORY 3 INSIGHT                                     ║
║                                                               ║
║  "Your father appears in all 3 stories. Tell me about        ║
║   the first time you disappointed him."                      ║
║                                                               ║
║  📍 Based on stories from 1955, 1960, 1982                   ║
║                                                               ║
║  ─────────────────────────────────────────────────────────   ║
║                                                               ║
║  💡 I've analyzed your first 3 stories and found             ║
║     3 more specific memories you should record.              ║
║                                                               ║
║  Ready to unlock your full story?                            ║
║                                                               ║
║     [See What I Found - $149/year]                           ║
║                                                               ║
║     [Maybe later]                                            ║
╚══════════════════════════════════════════════════════════════╝
                              ↓
                    User clicks "See What I Found"
                              ↓
                    Stripe checkout → Payment success
                              ↓
                    Webhook: POST /api/webhooks/stripe
                              ↓
                    Update users table:
                      subscription_status = 'active'
                              ↓
                    Unlock premium seed:
                      UPDATE active_prompts
                      SET is_locked = false,
                          expires_at = NOW() + INTERVAL '60 days'
                      WHERE user_id = $1 AND is_locked = true
                              ↓
                    User redirected to timeline
                              ↓
                    Sees 4 prompts available (1 original + 3 premium)
3.2 Paid Tier Flow (Stories 4+)


┌──────────────────────────────────────────────────────────────┐
│                   RECORDING STORY 4-20                        │
└──────────────────────────────────────────────────────────────┘

User records Story N
                              ↓
                    POST /api/stories
                              ↓
                    Save to database
                              ↓
                    Tier 1: Generate 1 template prompt (always)
                              ↓
                    Check if milestone (4,7,10,15,20,30,50,100)
                              ↓
                    YES → Tier 3 Analysis
                          - Stories 4-20: Generate 3 prompts
                          - Stories 30-50: Generate 2 prompts  
                          - Stories 100+: Generate 1 prompt
                              ↓
                    NO → Continue
                              ↓
                    Return success

┌──────────────────────────────────────────────────────────────┐
│                   EMPTY INVENTORY SCENARIO                    │
└──────────────────────────────────────────────────────────────┘

User opens timeline
                              ↓
                    GET /api/prompts/next
                              ↓
                    Query active_prompts WHERE:
                      - user_id = $1
                      - expires_at > NOW()
                      - is_locked = false
                              ↓
                    EMPTY RESULT
                              ↓
                    Check last_tier2_attempt timestamp
                              ↓
                    < 24 hours ago → Return decade fallback
                              ↓
                    ≥ 24 hours ago → Generate Tier 2 prompt
                                    - Fetch last 5 stories
                                    - GPT-4o analysis
                                    - Generate 5 candidates
                                    - Score and filter
                                    - Store top 2
                                    - Update last_tier2_attempt
                              ↓
                    Return prompt to client
3.3 Grace Period Flow (Non-Payer After Story 3)


Day 0: User records Story 3, sees paywall, clicks "Maybe later"
       - Can still VIEW timeline and stories
       - Cannot RECORD Story 4
       - Email: "Your Story 3 analysis is ready"

Day 1-6: User can browse read-only
         - Timeline shows all 3 stories
         - "Record" button shows paywall
         - Prompts visible but locked

Day 3: Email: "I found 3 more memories you should record"

Day 5: Email: "Last chance - your access expires in 2 days"

Day 7: Account goes read-only
       - Cannot record
       - Cannot view prompts
       - Can still see story titles (teaser)
       - Banner: "Subscribe to access your stories and prompts"

4. DATABASE SCHEMA
4.1 Schema Additions


sql
-- ============================================================================
-- ACTIVE PROMPTS TABLE
-- ============================================================================
-- Stores currently active prompts (1-5 per user at any time)
-- Prompts expire and are archived to prompt_history

CREATE TABLE active_prompts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  
  -- Prompt content
  prompt_text TEXT NOT NULL,
  context_note TEXT, -- e.g., "Based on your 1955 story"
  
  -- Deduplication & anchoring
  anchor_entity TEXT, -- e.g., "father's workshop", "Mrs. Henderson"
  anchor_year INTEGER, -- e.g., 1955 (NULL if not year-specific)
  anchor_hash TEXT NOT NULL, -- sha1(`${type}|${entity}|${year||'NA'}`)
  
  -- Tier & quality
  tier INTEGER NOT NULL, -- 0=fallback, 1=template, 2=on-demand, 3=milestone
  memory_type TEXT, -- person_expansion, object_origin, decade_gap, etc.
  prompt_score INTEGER, -- 0-100 (recording likelihood from GPT-4o)
  score_reason TEXT, -- 1-sentence explanation for audit
  model_version TEXT DEFAULT 'gpt-4o', -- Track which model generated it
  
  -- Lifecycle
  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP NOT NULL, -- Auto-cleanup after expiry
  is_locked BOOLEAN DEFAULT false, -- true = hidden until payment
  
  -- Engagement tracking
  shown_count INTEGER DEFAULT 0,
  last_shown_at TIMESTAMP,
  
  -- Constraints
  UNIQUE(user_id, anchor_hash) -- Prevent duplicate prompts
);

-- Indexes
CREATE INDEX idx_active_prompts_user ON active_prompts(user_id, expires_at DESC);
CREATE INDEX idx_active_prompts_tier ON active_prompts(tier, prompt_score DESC);
CREATE INDEX idx_active_prompts_locked ON active_prompts(user_id, is_locked);

-- ============================================================================
-- PROMPT HISTORY TABLE
-- ============================================================================
-- Archives used/skipped/expired prompts for analytics

CREATE TABLE prompt_history (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
  
  -- Original prompt data
  prompt_text TEXT NOT NULL,
  anchor_hash TEXT,
  anchor_entity TEXT,
  anchor_year INTEGER,
  tier INTEGER,
  memory_type TEXT,
  prompt_score INTEGER,
  
  -- Outcome tracking
  shown_count INTEGER,
  outcome TEXT NOT NULL, -- 'used' | 'skipped' | 'expired'
  story_id UUID, -- NULL if skipped/expired, set if used
  
  -- Timestamps
  created_at TIMESTAMP,
  resolved_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_prompt_history_outcome ON prompt_history(user_id, outcome, tier);
CREATE INDEX idx_prompt_history_story ON prompt_history(story_id) WHERE story_id IS NOT NULL;

-- ============================================================================
-- USERS TABLE ADDITIONS
-- ============================================================================
-- Add columns to existing users table

ALTER TABLE users ADD COLUMN IF NOT EXISTS free_stories_used INTEGER DEFAULT 0;
ALTER TABLE users ADD COLUMN IF NOT EXISTS subscription_status TEXT DEFAULT 'none';
-- Values: 'none', 'active', 'cancelled', 'expired'

ALTER TABLE users ADD COLUMN IF NOT EXISTS last_tier2_attempt TIMESTAMP;
-- Rate limit Tier 2 on-demand generation (max 1 per 24 hours)

ALTER TABLE users ADD COLUMN IF NOT EXISTS do_not_ask JSONB DEFAULT '[]'::jsonb;
-- Array of topics user doesn't want to be asked about
-- Example: ["divorce", "mother's death", "bankruptcy"]

ALTER TABLE users ADD COLUMN IF NOT EXISTS onboarding_t3_ran_at TIMESTAMP;
-- Track when Story 1/2/3 analysis ran (for debugging)

-- ============================================================================
-- STORIES TABLE ADDITIONS
-- ============================================================================
-- Add column to track which prompt generated this story

ALTER TABLE stories ADD COLUMN IF NOT EXISTS source_prompt_id UUID;
-- References active_prompts.id (but not FK since prompt gets deleted)

CREATE INDEX idx_stories_source_prompt ON stories(source_prompt_id) 
WHERE source_prompt_id IS NOT NULL;

-- ============================================================================
-- CLEANUP JOB (Daily)
-- ============================================================================
-- Archive expired prompts and clean up old history

CREATE OR REPLACE FUNCTION archive_expired_prompts() RETURNS void AS $$
BEGIN
  -- Move expired prompts to history
  INSERT INTO prompt_history (
    user_id, prompt_text, anchor_hash, anchor_entity, anchor_year,
    tier, memory_type, prompt_score, shown_count, outcome, created_at
  )
  SELECT 
    user_id, prompt_text, anchor_hash, anchor_entity, anchor_year,
    tier, memory_type, prompt_score, shown_count, 'expired', created_at
  FROM active_prompts
  WHERE expires_at < NOW() AND is_locked = false;
  
  -- Delete expired prompts
  DELETE FROM active_prompts 
  WHERE expires_at < NOW() AND is_locked = false;
  
  -- Delete old history (keep 1 year)
  DELETE FROM prompt_history 
  WHERE resolved_at < NOW() - INTERVAL '365 days';
END;
$$ LANGUAGE plpgsql;

-- Schedule daily (use pg_cron or external scheduler)

5. API SPECIFICATIONS
5.1 POST /api/stories
Purpose: Save a new story and trigger prompt generation
Request:


typescript
POST /api/stories
Authorization: Bearer {jwt_token}
Content-Type: application/json

{
  "storyYear": 1955,
  "transcript": "I was 23 when I decided to leave medical school...",
  "audioUrl": "https://supabase.co/storage/...",
  "photos": [
    { "url": "https://...", "heroPhoto": true }
  ],
  "sourcePromptId": "uuid-of-prompt-if-applicable" // Optional
}
Response:


typescript
{
  "success": true,
  "story": {
    "id": "story-uuid",
    "storyYear": 1955,
    "transcript": "...",
    "createdAt": "2025-01-04T12:00:00Z"
  },
  "promptsGenerated": {
    "tier1": 1,  // Template prompt
    "tier3": 2   // Milestone prompts (if applicable)
  }
}
Server-Side Logic:


typescript
async function handleStoryCreate(req, res) {
  const userId = req.user.id;
  const { storyYear, transcript, audioUrl, photos, sourcePromptId } = req.body;
  
  // 1. Save story to database
  const story = await db.stories.create({
    userId,
    storyYear,
    transcript,
    audioUrl,
    photos,
    sourcePromptId,
    createdAt: new Date()
  });
  
  // 2. Update free_stories_used counter
  const user = await db.users.findById(userId);
  const freeStoriesUsed = user.free_stories_used + 1;
  await db.users.update(userId, { free_stories_used: freeStoriesUsed });
  
  // 3. Mark source prompt as used (if applicable)
  if (sourcePromptId) {
    const prompt = await db.active_prompts.findById(sourcePromptId);
    
    // Archive to history
    await db.prompt_history.create({
      userId,
      promptText: prompt.prompt_text,
      anchorHash: prompt.anchor_hash,
      anchorEntity: prompt.anchor_entity,
      tier: prompt.tier,
      memoryType: prompt.memory_type,
      promptScore: prompt.prompt_score,
      shownCount: prompt.shown_count,
      outcome: 'used',
      storyId: story.id,
      createdAt: prompt.created_at
    });
    
    // Delete from active
    await db.active_prompts.delete(sourcePromptId);
  }
  
  // 4. Generate Tier 1 template prompt (synchronous, fast)
  const tier1Prompt = generateTier1Template(transcript, storyYear);
  if (tier1Prompt) {
    await db.active_prompts.create({
      userId,
      promptText: tier1Prompt.text,
      contextNote: tier1Prompt.context,
      anchorEntity: tier1Prompt.entity,
      anchorYear: storyYear,
      anchorHash: generateAnchorHash(tier1Prompt),
      tier: 1,
      memoryType: tier1Prompt.type,
      expiresAt: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000) // 7 days
    });
  }
  
  // 5. Check for Tier 3 milestone
  const storyCount = await db.stories.count({ userId });
  const milestones = [1, 2, 3, 4, 7, 10, 15, 20, 30, 50, 100];
  
  if (milestones.includes(storyCount)) {
    // Queue background job for Tier 3 analysis
    await queue.add('generate-tier3-prompts', {
      userId,
      storyCount,
      isFreeTier: freeStoriesUsed <= 3
    });
  }
  
  return res.json({
    success: true,
    story,
    promptsGenerated: {
      tier1: tier1Prompt ? 1 : 0,
      tier3: milestones.includes(storyCount) ? 'queued' : 0
    }
  });
}

5.2 GET /api/prompts/next
Purpose: Get the next prompt to show in "Next Story" card
Request:


typescript
GET /api/prompts/next
Authorization: Bearer {jwt_token}
Response:


typescript
// Success - Prompt found
{
  "prompt": {
    "id": "prompt-uuid",
    "text": "What happened the morning after you told your father?",
    "contextNote": "Based on your 1955 story",
    "anchorEntity": "father's workshop",
    "tier": 3,
    "promptScore": 87
  }
}

// Success - Paywall (free user with 3+ stories)
{
  "paywall": true,
  "message": "Subscribe to unlock your personalized prompts",
  "premiumPromptsWaiting": 3
}

// Success - No prompts, generated new one
{
  "prompt": {
    "id": "prompt-uuid",
    "text": "Tell me about a typical Saturday in the 1960s.",
    "tier": 2,
    "promptScore": 72
  },
  "generated": true
}
Server-Side Logic:


typescript
async function getNextPrompt(req, res) {
  const userId = req.user.id;
  const user = await db.users.findById(userId);
  
  // 1. Check if user hit paywall
  if (user.subscription_status === 'none' && user.free_stories_used >= 3) {
    const lockedCount = await db.active_prompts.count({
      userId,
      isLocked: true
    });
    
    return res.json({
      paywall: true,
      message: "Subscribe to unlock your personalized prompts",
      premiumPromptsWaiting: lockedCount
    });
  }
  
  // 2. Try to fetch existing active prompt
  const prompt = await db.active_prompts.findOne({
    where: {
      userId,
      expiresAt: { $gt: new Date() },
      isLocked: false
    },
    orderBy: [
      ['tier', 'DESC'],           // Tier 3 > Tier 2 > Tier 1
      ['promptScore', 'DESC'],     // Higher score first
      ['shownCount', 'ASC'],       // Prefer unseen
      ['createdAt', 'DESC']        // Prefer recent
    ]
  });
  
  if (prompt) {
    // Increment shown count
    await db.active_prompts.update(prompt.id, {
      shownCount: prompt.shown_count + 1,
      lastShownAt: new Date()
    });
    
    return res.json({ prompt });
  }
  
  // 3. No active prompts - check Tier 2 rate limit
  const lastAttempt = user.last_tier2_attempt;
  const hoursSinceLastAttempt = lastAttempt 
    ? (Date.now() - lastAttempt.getTime()) / (1000 * 60 * 60)
    : 999;
  
  if (hoursSinceLastAttempt < 24) {
    // Rate limited - return decade fallback
    const fallback = await generateDecadeFallback(userId);
    return res.json({ prompt: fallback });
  }
  
  // 4. Generate Tier 2 on-demand prompt
  try {
    await db.users.update(userId, { last_tier2_attempt: new Date() });
    const tier2Prompt = await generateTier2Prompt(userId);
    
    if (tier2Prompt) {
      return res.json({ prompt: tier2Prompt, generated: true });
    } else {
      // Generation failed - fallback
      const fallback = await generateDecadeFallback(userId);
      return res.json({ prompt: fallback });
    }
  } catch (error) {
    // API error - fallback
    const fallback = await generateDecadeFallback(userId);
    return res.json({ prompt: fallback });
  }
}

5.3 POST /api/prompts/skip
Purpose: User clicked "Skip" on a prompt
Request:


typescript
POST /api/prompts/skip
Authorization: Bearer {jwt_token}
Content-Type: application/json

{
  "promptId": "prompt-uuid"
}
Response:


typescript
{
  "success": true,
  "nextPrompt": {
    "id": "next-prompt-uuid",
    "text": "Tell me about your mother...",
    // ... full prompt object
  }
}
Server-Side Logic:


typescript
async function handlePromptSkip(req, res) {
  const userId = req.user.id;
  const { promptId } = req.body;
  
  const prompt = await db.active_prompts.findById(promptId);
  
  if (!prompt || prompt.user_id !== userId) {
    return res.status(404).json({ error: 'Prompt not found' });
  }
  
  // Increment shown count
  const newShownCount = prompt.shown_count + 1;
  
  // Retire prompt if skipped 3+ times
  if (newShownCount >= 3) {
    // Archive to history
    await db.prompt_history.create({
      userId,
      promptText: prompt.prompt_text,
      anchorHash: prompt.anchor_hash,
      tier: prompt.tier,
      memoryType: prompt.memory_type,
      promptScore: prompt.prompt_score,
      shownCount: newShownCount,
      outcome: 'skipped',
      createdAt: prompt.created_at
    });
    
    // Delete from active
    await db.active_prompts.delete(promptId);
  } else {
    // Just increment skip count
    await db.active_prompts.update(promptId, {
      shownCount: newShownCount,
      lastShownAt: new Date()
    });
  }
  
  // Return next prompt
  const nextPrompt = await getNextPrompt({ user: { id: userId } }, res);
  return res.json({ success: true, nextPrompt });
}

5.4 POST /api/webhooks/stripe
Purpose: Handle Stripe subscription webhook (payment success)
Request:


typescript
POST /api/webhooks/stripe
Stripe-Signature: {signature}
Content-Type: application/json

{
  "type": "checkout.session.completed",
  "data": {
    "object": {
      "customer": "cus_xxx",
      "client_reference_id": "user-uuid",
      "payment_status": "paid"
    }
  }
}
Server-Side Logic:


typescript
async function handleStripeWebhook(req, res) {
  const event = req.body;
  
  if (event.type === 'checkout.session.completed') {
    const userId = event.data.object.client_reference_id;
    
    // 1. Update subscription status
    await db.users.update(userId, {
      subscription_status: 'active',
      subscription_started_at: new Date()
    });
    
    // 2. Unlock premium seed prompts (from Story 3)
    await db.active_prompts.updateMany(
      {
        userId,
        isLocked: true
      },
      {
        isLocked: false,
        expiresAt: new Date(Date.now() + 60 * 24 * 60 * 60 * 1000) // 60 days
      }
    );
    
    // 3. Send welcome email (optional)
    await sendEmail({
      to: user.email,
      subject: "Welcome to HeritageWhisper Premium!",
      body: "Your personalized prompts are now unlocked..."
    });
    
    return res.json({ received: true });
  }
  
  // Handle other events (subscription cancelled, etc.)
  // ...
}

6. AI PROMPT TEMPLATES
6.1 Story 1 Analysis (Free Tier)
Purpose: Expand a single story to find implied moments
OpenAI Request:


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.7,
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are analyzing the FIRST story someone shared. Your job is to find what was IMPLIED but not fully told in this ONE story.

Generate 5 candidate prompts that expand THIS story (not find gaps, there aren't any yet).

LOOK FOR:

1. THE MOMENT BEFORE
   - They jumped into the middle. What led up to this?
   - "I decided to leave" → What happened the day before you decided?

2. THE MOMENT AFTER
   - They told the decision, not the aftermath
   - "I quit medical school" → What happened the next morning?

3. OTHER PEOPLE IMPLIED
   - "My father was disappointed" → What did your mother say?
   - "Mrs. Henderson taught me" → Who else was in that classroom?

4. SENSORY GAPS
   - They told WHAT happened, not what it felt/looked/smelled like
   - "The workshop" → What did it smell like in there?

5. IMPLIED BACKSTORY
   - They referenced something without explaining it
   - "That old watch" → Where did that watch come from?

GENERATE 5 PROMPTS THAT:
✅ Ask about something SPECIFIC from this story
✅ Feel like you're genuinely curious (not generic)
✅ Make them think: "Oh wow, it actually read my story"
✅ Trigger recording (not analysis)

For EACH prompt, you must also generate:
- A recording_likelihood score (0-100)
- A brief reasoning (1 sentence)

The scoring criteria:
- Specificity: References exact people/places/objects from story
- Emotional resonance: Triggers feeling, not just facts
- Kindness: Curious, not confrontational
- Recording likelihood: Will they hit "Record" or "Skip"?

EXAMPLES OF GOOD PROMPTS:

Story: "I decided to leave medical school in 1982..."
GOOD: "What happened the morning you walked into the dean's office to quit?"
Score: 85
Reasoning: Asks about specific implied moment with sensory potential

BAD: "Tell me about another big decision"
Score: 30
Reasoning: Too generic, could apply to anyone

Story: "My father's workshop was where I learned discipline..."
GOOD: "Who else spent time in that workshop with you and your father?"
Score: 80
Reasoning: Expands on mentioned place, asks about implied people

BAD: "What did discipline mean to you?"
Score: 40
Reasoning: Too abstract for memory recall

Return JSON in this exact format:
{
  "candidates": [
    {
      "prompt": "What happened the morning after you told your father?",
      "trigger": "moment_after",
      "anchor_entity": "father",
      "anchor_year": 1955,
      "recording_likelihood": 87,
      "reasoning": "Asks about implied next-day moment with emotional weight"
    },
    // ... 4 more candidates
  ]
}

Sort candidates by recording_likelihood DESC.`
    },
    {
      role: 'user',
      content: `Story Year: ${storyYear}

Transcript:
${transcript}

Generate 5 expansion prompts for this first story.`
    }
  ]
});
Expected Response:


json
{
  "candidates": [
    {
      "prompt": "What happened the very next morning after you quit medical school?",
      "trigger": "moment_after",
      "anchor_entity": "medical school",
      "anchor_year": 1982,
      "recording_likelihood": 88,
      "reasoning": "Immediate aftermath creates strong narrative pull"
    },
    {
      "prompt": "What was on your father's face when you told him you were quitting?",
      "trigger": "implied_emotion",
      "anchor_entity": "father",
      "anchor_year": 1982,
      "recording_likelihood": 85,
      "reasoning": "Sensory detail about pivotal emotional moment"
    },
    {
      "prompt": "Who was the first person you called after making that decision?",
      "trigger": "implied_person",
      "anchor_entity": "decision to quit",
      "anchor_year": 1982,
      "recording_likelihood": 78,
      "reasoning": "Reveals support system and emotional processing"
    },
    {
      "prompt": "Where were you standing when you made the final decision to leave?",
      "trigger": "missing_sensory",
      "anchor_entity": "decision moment",
      "anchor_year": 1982,
      "recording_likelihood": 72,
      "reasoning": "Spatial memory anchors the turning point"
    },
    {
      "prompt": "What did you almost do instead of quitting?",
      "trigger": "moment_before",
      "anchor_entity": "decision",
      "anchor_year": 1982,
      "recording_likelihood": 68,
      "reasoning": "Reveals internal conflict and alternatives considered"
    }
  ]
}

6.2 Story 2 Analysis (Free Tier)
Purpose: Light connection between two stories or deeper expansion
OpenAI Request:


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.7,
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are analyzing the first 2 stories someone has shared.

Generate 4 candidate prompts that either:
A) Expand one of these stories (like Story 1 approach)
B) Connect these two stories (if there's a meaningful connection)

LOOK FOR CONNECTIONS:
- Same person mentioned in both stories
- Same emotion in both stories (pride, fear, etc)
- Same location/setting in different times
- Opposite outcomes (success vs failure, joy vs grief)
- Time gap worth exploring (what happened between?)

CONNECTION PROMPTS (if connections exist):
- "You mentioned [person] in both stories. Tell me about the first time you met them."
- "You felt [emotion] in both moments. Tell me about another time you felt that way."
- "Story 1 was in [year], Story 2 in [year]. What happened between those years?"

EXPANSION PROMPTS (if no clear connection):
- Use Story 1 techniques on whichever story has more expansion potential
- Focus on sensory details, implied people, moment before/after

SCORING:
For each prompt:
- recording_likelihood (0-100)
- reasoning (1 sentence)

Criteria:
- Connection prompts score higher IF connection is meaningful
- Expansion prompts score based on specificity and emotional resonance
- Avoid forced connections (if stories are unrelated, expand instead)

Return JSON:
{
  "candidates": [
    {
      "prompt": "...",
      "trigger": "person_connection" | "emotion_connection" | "expansion",
      "anchor_entity": "...",
      "anchor_year": null,  // or specific year
      "recording_likelihood": 0-100,
      "reasoning": "..."
    },
    // ... 3 more
  ]
}

Sort by recording_likelihood DESC.`
    },
    {
      role: 'user',
      content: `Story 1 (${story1Year}):
${story1Transcript}

Story 2 (${story2Year}):
${story2Transcript}

Generate 4 prompts that either connect these stories or expand on them.`
    }
  ]
});

6.3 Story 3 Analysis (Free Tier) - THE KILLER PROMPT
Purpose: Generate THE BEST prompt to convince user to pay
OpenAI Request:


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.8, // Slightly higher for creativity
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are analyzing 3 stories to generate the MOST COMPELLING prompt possible.

This is a free user deciding whether to pay $149/year. This prompt must be EXCEPTIONAL.

Generate 5 candidate prompts. We will show ONLY the best one.

PRIORITY ORDER:

1. STRONG PATTERN (if exists)
   - Same person in 2+ stories → Ask about that relationship
   - Same emotion in 2+ stories → Ask about that feeling's origin
   - Recurring theme/value → Surface it directly
   Example: "Your father appears in all 3 stories but you've never told me about him directly. Tell me about your father."

2. COMPELLING GAP (if exists)
   - 30+ year gap between stories → Ask what happened in between
   - All positive → Ask about challenge/failure
   - All about work → Ask about family/love
   Example: "You've shared stories from 1955, 1960, and 1995. What happened in the 1970s and 80s?"

3. DEEP EXPANSION (fallback)
   - Pick the most emotionally resonant story
   - Ask about implied moment that carries weight
   Example: "That workshop you keep mentioning - tell me about the last time you were there with your father."

THE GOAL:
Make them think: "Holy shit, this thing GETS me. I need to pay for this."

SCORING:
Each prompt gets:
- recording_likelihood (0-100)
- conversion_likelihood (0-100) ← NEW: Will this make them pay?
- reasoning (1-2 sentences)

Criteria for conversion_likelihood:
- Shows AI "read between the lines" (not obvious)
- Personal (couldn't ask this of anyone else)
- Emotionally resonant (touches something deep)
- Creates curiosity ("I want to know what else it found")

AVOID:
- Generic questions that could apply to anyone
- "Why" questions (too analytical)
- Abstract themes without specific anchors
- Anything that feels like therapy instead of curiosity

Return JSON:
{
  "candidates": [
    {
      "prompt": "...",
      "trigger": "strong_pattern" | "compelling_gap" | "deep_expansion",
      "anchor_entity": "...",
      "anchor_year": null,
      "recording_likelihood": 0-100,
      "conversion_likelihood": 0-100,
      "reasoning": "..."
    },
    // ... 4 more
  ]
}

Sort by: conversion_likelihood DESC, then recording_likelihood DESC.`
    },
    {
      role: 'user',
      content: `Story 1 (${story1Year}):
${story1Transcript}

Story 2 (${story2Year}):
${story2Transcript}

Story 3 (${story3Year}):
${story3Transcript}

Generate 5 prompts. We need THE BEST one to show before the paywall.`
    }
  ]
});

6.4 Tier 2 On-Demand (Paid Users)
Purpose: Generate prompts when inventory is empty
OpenAI Request:


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.7,
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are a memory activation specialist helping seniors remember forgotten life stories.

Your job: Generate 5 prompts that trigger SPECIFIC memories they haven't recorded yet.

You have access to their last 3-5 stories. Find what's IMPLIED but not told.

LOOK FOR:

1. PEOPLE MENTIONED IN PASSING
   - Name appears but no dedicated story
   - "My brother said..." → Ask about brother's full story
   - "Mrs. Henderson taught me..." → Ask about first day in her class

2. OBJECTS WITH BACKSTORIES
   - "That old watch" → Where did it come from?
   - "The family car" → First time driving it?
   - Any possession mentioned without origin story

3. PLACES THAT HOLD MEMORIES
   - "The workshop" → What did it smell like?
   - "Our apartment" → Describe the kitchen
   - Locations referenced but not fully described

4. MOMENTS IMPLIED BUT NOT TOLD
   - "After we got married..." → What about the wedding day?
   - "When I left medical school..." → What about the decision moment?
   - Any before/after gap

5. SENSORY OR EMOTIONAL SPIKES
   - "I was terrified" → What did fear feel like in your body?
   - "The smell of sawdust..." → What else triggers that memory?
   - Strong emotions or senses mentioned without full context

6. TIME GAPS
   - Stories from 1955 and 1995 → What about the decades in between?
   - All stories from one era → Ask about different decade

GENERATE 5 PROMPTS THAT:
✅ Use specific details from THEIR stories (names, places, years)
✅ Ask about concrete moments, not abstract themes
✅ Trigger sensory memory (sight, sound, smell, touch, taste)
✅ Feel like a curious grandchild, not a therapist
✅ High probability of "Oh! I should record that!"

SCORING:
- recording_likelihood (0-100)
- specificity_score (0-100) ← How specific vs generic
- reasoning (1 sentence)

EXAMPLES OF GOOD PROMPTS:
- "You mentioned your father's workshop in two stories. What tool did he use most?" (Score: 85)
- "Mrs. Henderson - what did her classroom smell like?" (Score: 82)
- "That rejection letter from medical school - where were you when you opened it?" (Score: 88)

EXAMPLES OF BAD PROMPTS:
- "Tell me about your relationship with your father" (Too broad)
- "What did family mean to you?" (Too abstract)
- "Why did you become a teacher?" (Too analytical)

Return JSON:
{
  "candidates": [
    {
      "prompt": "...",
      "trigger": "implied_person" | "object_backstory" | "missing_sensory" | etc,
      "anchor_entity": "...",
      "anchor_year": null,
      "recording_likelihood": 0-100,
      "specificity_score": 0-100,
      "reasoning": "..."
    },
    // ... 4 more
  ]
}

Sort by recording_likelihood DESC.`
    },
    {
      role: 'user',
      content: `Recent stories:

${recentStories.map((s, i) => `Story ${i+1} (${s.year}):
${s.transcript.slice(0, 800)}...`).join('\n\n')}

Generate 5 prompts based on these stories.`
    }
  ]
});

6.5 Tier 3 Milestone Analysis (Paid Users)
Purpose: Deep pattern detection across ALL stories at milestones
Two Versions: Discovery (Stories 4-20) vs Pattern (Stories 30+)
Discovery Phase (Stories 4-20):


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.7,
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are analyzing early life stories (4-20 total) to find memory triggers.

This person is building their story collection. Generate 3 prompts that fill obvious gaps.

PRIORITY 1: FILL GAPS
- Person mentioned 2+ times but no dedicated story
- Decade with only 1 story (ask about another moment)
- Relationship mentioned but not explored (spouse, parent, sibling)
- Location that appears repeatedly but never described

PRIORITY 2: EMOTIONAL RANGE
- All happy stories? → Ask about challenge/failure
- All work stories? → Ask about family/play
- All serious? → Ask about joy/silly moment
- All success? → Ask about learning from failure

PRIORITY 3: BEFORE/AFTER MOMENTS
- Big decision told → What came before?
- Success told → What about the struggle?
- Ending told → What about the beginning?

AVOID:
- Abstract pattern analysis (save for 30+ stories)
- Contradictions (not enough data yet)
- Generic prompts

Generate 3 prompts ranked by recording likelihood.

Return JSON:
{
  "prompts": [
    {
      "prompt": "...",
      "gap_type": "person_expansion" | "decade_gap" | "emotional_balance" | "before_after",
      "anchor_entity": "...",
      "priority": 0-100,
      "reasoning": "..."
    },
    // ... 2 more
  ]
}

Sort by priority DESC.`
    },
    {
      role: 'user',
      content: `This person has ${storyCount} stories:

${allStories.map((s, i) => `${i+1}. ${s.year}: ${s.transcript.slice(0, 400)}...`).join('\n\n')}

Generate 3 prompts that fill gaps in their early collection.`
    }
  ]
});
Pattern Phase (Stories 30+):


typescript
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  temperature: 0.8,
  response_format: { type: 'json_object' },
  messages: [
    {
      role: 'system',
      content: `You are analyzing a substantial life story collection (30+ stories).

This person is committed. NOW you can do sophisticated analysis.

LOOK FOR:

1. CROSS-STORY CONTRADICTIONS
   - "Family first" said 3 times, but worked weekends mentioned 5 times
   - Values stated vs behaviors shown
   - Ask about the tension, not accusatorily

2. RECURRING PHRASES/VALUES
   - Same words/phrases used 3+ times
   - Patterns in decision-making
   - Core values that keep appearing

3. CHARACTER TENSIONS
   - Discipline vs spontaneity
   - Duty vs desire
   - Independence vs connection

4. UNRESOLVED QUESTIONS ACROSS DECADES
   - Decision in 1960s → consequence in 1990s
   - Relationship arc over 40 years
   - Evolution of values over time

5. MAJOR GAPS STILL REMAINING
   - Entire decades missing
   - Important people never fully explored
   - Life stages skipped (marriage, parenthood, retirement)

Generate 1-2 prompts (depending on milestone: 30/50=2, 100=1) that:
- Connect distant stories
- Surface invisible rules they lived by
- Ask about tensions, not just facts
- Create "I've never thought about it that way" moments

SCORING:
- insight_depth (0-100) ← How profound vs surface
- recording_likelihood (0-100)
- reasoning (2-3 sentences)

EXAMPLES:

"You mentioned having 'no choice' in stories from 1965, 1978, and 1992. Tell me about a time you DID have a choice but were afraid to take it." (Insight: 92, Recording: 85)

"Your story about forgiving your father in 1995 and your story about raising your son in 2005 - how did one shape the other?" (Insight: 88, Recording: 78)

Return JSON:
{
  "prompts": [
    {
      "prompt": "...",
      "pattern_type": "contradiction" | "recurring_value" | "character_tension" | "time_connection",
      "anchor_entity": "...",
      "insight_depth": 0-100,
      "recording_likelihood": 0-100,
      "reasoning": "..."
    },
    // 0-1 more depending on milestone
  ]
}

Sort by: insight_depth DESC, recording_likelihood DESC.`
    },
    {
      role: 'user',
      content: `This person has ${storyCount} stories spanning ${yearRange} years.

${allStories.map((s, i) => `${i+1}. ${s.year}: ${s.transcript.slice(0, 300)}...`).join('\n\n')}

Generate ${promptCount} deep insight prompt(s).`
    }
  ]
});

7. BUSINESS LOGIC & ALGORITHMS
7.1 Tier 1 Template Generation
Function: Extract entities and match templates


typescript
// ============================================================================
// ENTITY EXTRACTION
// ============================================================================

interface ExtractedEntities {
  people: string[];
  places: string[];
  objects: string[];
  emotions: string[];
  temporalBoundaries: string[];
}

function extractEntities(transcript: string): ExtractedEntities {
  // Normalize text (case-insensitive matching)
  const normalized = transcript.toLowerCase();
  
  // Extract people (proper nouns followed by action verbs)
  const peoplePatterns = [
    /\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)\s+(said|told|taught|showed|gave|asked|wanted|helped|loved)/gi,
    /my\s+(?:friend|teacher|father|mother|brother|sister|boss|mentor)\s+([A-Z][a-z]+)/gi
  ];
  
  const people = new Set<string>();
  peoplePatterns.forEach(pattern => {
    const matches = transcript.matchAll(pattern);
    for (const match of matches) {
      people.add(match[1]);
    }
  });
  
  // Extract places (prepositions + capitalized locations)
  const placePatterns = [
    /\b(?:at|in|near|by|to)\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)/g,
    /\b(?:the)\s+(workshop|office|house|apartment|school|church|hospital|factory)/gi
  ];
  
  const places = new Set<string>();
  placePatterns.forEach(pattern => {
    const matches = transcript.matchAll(pattern);
    for (const match of matches) {
      places.add(match[1]);
    }
  });
  
  // Extract objects (possessives + concrete nouns)
  const objectPatterns = [
    /\b(?:my|his|her|our|their|the)\s+([\w\s]+?)\s+(?:that|which|was|had|sat|hung)/gi
  ];
  
  const objects = new Set<string>();
  objectPatterns.forEach(pattern => {
    const matches = normalized.matchAll(pattern);
    for (const match of matches) {
      const obj = match[1].trim();
      // Filter out common words
      if (obj.length > 3 && !['that', 'this', 'there', 'thing'].includes(obj)) {
        objects.add(obj);
      }
    }
  });
  
  // Extract emotions
  const emotionWords = [
    'proud', 'scared', 'angry', 'happy', 'sad', 'disappointed', 
    'excited', 'nervous', 'ashamed', 'relieved', 'terrified',
    'joyful', 'anxious', 'grateful', 'regretful'
  ];
  
  const emotions = emotionWords.filter(emotion => 
    normalized.includes(emotion)
  );
  
  // Extract temporal boundaries
  const temporalPatterns = [
    /(first|last|only)\s+time/gi
  ];
  
  const temporalBoundaries: string[] = [];
  temporalPatterns.forEach(pattern => {
    const matches = transcript.matchAll(pattern);
    for (const match of matches) {
      temporalBoundaries.push(match[0]);
    }
  });
  
  return {
    people: Array.from(people),
    places: Array.from(places),
    objects: Array.from(objects),
    emotions,
    temporalBoundaries
  };
}

// ============================================================================
// TEMPLATE LIBRARY
// ============================================================================

interface PromptTemplate {
  trigger: string;
  patterns: string[];
  context: string;
  priority: number;
}

const TEMPLATE_LIBRARY: Record<string, PromptTemplate> = {
  person_expansion: {
    trigger: 'person_mentioned',
    patterns: [
      "Tell me about the first time you met {person}.",
      "What's the clearest memory you have of {person}?",
      "{person} sounds important. What did they teach you?",
      "What did {person} look like? Describe them.",
      "What's something {person} said that you've never forgotten?"
    ],
    context: "You mentioned {person} in your recent story",
    priority: 90
  },
  
  object_origin: {
    trigger: 'object_mentioned',
    patterns: [
      "Where did your {object} come from?",
      "Tell me the story of how you got {object}.",
      "Do you still have {object}? What happened to it?",
      "Who gave you {object}?",
      "What's the first memory you have with {object}?"
    ],
    context: "You mentioned {object}",
    priority: 85
  },
  
  place_memory: {
    trigger: 'place_mentioned',
    patterns: [
      "What's your first memory of {place}?",
      "Describe {place}. If I walked in, what would I see?",
      "What did {place} smell like?",
      "Who else was usually at {place}?",
      "Tell me about the last time you were at {place}."
    ],
    context: "You mentioned {place}",
    priority: 88
  },
  
  emotion_expansion: {
    trigger: 'emotion_detected',
    patterns: [
      "Tell me about another time you felt {emotion} like that.",
      "What's the most {emotion} you've ever been?",
      "Who else was there when you felt {emotion}?",
      "Where in your body did you feel that {emotion}?"
    ],
    context: "You felt {emotion}",
    priority: 75
  },
  
  temporal_sequence: {
    trigger: 'temporal_boundary',
    patterns: [
      "What happened right after that {temporal} time?",
      "Tell me about the {opposite_temporal} time.",
      "What led up to that {temporal} time?"
    ],
    context: "You mentioned a {temporal} time",
    priority: 70
  }
};

// ============================================================================
// TEMPLATE MATCHING
// ============================================================================

interface Tier1Prompt {
  text: string;
  context: string;
  entity: string;
  type: string;
  anchorHash: string;
}

function generateTier1Template(
  transcript: string, 
  storyYear: number
): Tier1Prompt | null {
  const entities = extractEntities(transcript);
  
  // Priority order (most likely to trigger recording)
  if (entities.people.length > 0) {
    const person = entities.people[0];
    const template = TEMPLATE_LIBRARY.person_expansion;
    const pattern = template.patterns[Math.floor(Math.random() * template.patterns.length)];
    
    return {
      text: pattern.replace('{person}', person),
      context: template.context.replace('{person}', person),
      entity: person,
      type: 'person_expansion',
      anchorHash: generateAnchorHash('person_expansion', person, storyYear)
    };
  }
  
  if (entities.objects.length > 0) {
    const object = entities.objects[0];
    const template = TEMPLATE_LIBRARY.object_origin;
    const pattern = template.patterns[Math.floor(Math.random() * template.patterns.length)];
    
    return {
      text: pattern.replace('{object}', object),
      context: template.context.replace('{object}', object),
      entity: object,
      type: 'object_origin',
      anchorHash: generateAnchorHash('object_origin', object, storyYear)
    };
  }
  
  if (entities.places.length > 0) {
    const place = entities.places[0];
    const template = TEMPLATE_LIBRARY.place_memory;
    const pattern = template.patterns[Math.floor(Math.random() * template.patterns.length)];
    
    return {
      text: pattern.replace('{place}', place),
      context: template.context.replace('{place}', place),
      entity: place,
      type: 'place_memory',
      anchorHash: generateAnchorHash('place_memory', place, storyYear)
    };
  }
  
  if (entities.emotions.length > 0) {
    const emotion = entities.emotions[0];
    const template = TEMPLATE_LIBRARY.emotion_expansion;
    const pattern = template.patterns[Math.floor(Math.random() * template.patterns.length)];
    
    return {
      text: pattern.replace('{emotion}', emotion),
      context: template.context.replace('{emotion}', emotion),
      entity: emotion,
      type: 'emotion_expansion',
      anchorHash: generateAnchorHash('emotion_expansion', emotion, storyYear)
    };
  }
  
  // Fallback: decade-based generic
  const decade = Math.floor(storyYear / 10) * 10;
  return {
    text: `What was a typical Saturday like in the ${decade}s?`,
    context: `Based on your ${storyYear} story`,
    entity: `${decade}s`,
    type: 'decade_context',
    anchorHash: generateAnchorHash('decade_context', `${decade}s`, decade)
  };
}

// ============================================================================
// ANCHOR HASH GENERATION
// ============================================================================

function generateAnchorHash(
  type: string, 
  entity: string, 
  year: number | null
): string {
  const crypto = require('crypto');
  const normalized = entity.toLowerCase().trim();
  const yearStr = year ? year.toString() : 'NA';
  const input = `${type}|${normalized}|${yearStr}`;
  
  return crypto.createHash('sha1').update(input).digest('hex');
}

7.2 Generate-and-Filter Algorithm
Function: Generate multiple candidates, score, filter, store best


typescript
// ============================================================================
// SCORE FILTERING
// ============================================================================

interface ScoredPrompt {
  prompt: string;
  trigger: string;
  anchorEntity: string;
  anchorYear: number | null;
  recordingLikelihood: number;
  reasoning: string;
}

async function generateAndFilterPrompts(
  userId: string,
  tier: number,
  context: any
): Promise<void> {
  // 1. Generate candidates based on tier
  let candidates: ScoredPrompt[];
  
  if (tier === 1) {
    // Template generation (handled separately)
    return;
  } else if (tier === 2) {
    // On-demand generation
    candidates = await generateTier2Candidates(userId);
  } else if (tier === 3) {
    // Milestone generation
    candidates = await generateTier3Candidates(userId, context.storyCount);
  }
  
  // 2. Filter by minimum score threshold
  const MIN_SCORE = 50;
  const filtered = candidates.filter(c => c.recordingLikelihood >= MIN_SCORE);
  
  if (filtered.length === 0) {
    // All candidates scored too low - retry with different approach
    console.warn(`All candidates scored below ${MIN_SCORE} for user ${userId}`);
    
    if (tier === 3 && context.isFreeTier) {
      // Free tier failure is critical - retry once with sensory focus
      candidates = await generateTier3Candidates(userId, context.storyCount, 'sensory_only');
      const retryFiltered = candidates.filter(c => c.recordingLikelihood >= MIN_SCORE);
      
      if (retryFiltered.length === 0) {
        // Still failed - use decade fallback
        const fallback = await generateDecadeFallback(userId);
        await storePrompt(userId, fallback, tier);
        return;
      }
      
      filtered.push(...retryFiltered);
    } else {
      // Paid tier failure - just use decade fallback
      const fallback = await generateDecadeFallback(userId);
      await storePrompt(userId, fallback, tier);
      return;
    }
  }
  
  // 3. Sort by score descending
  filtered.sort((a, b) => b.recordingLikelihood - a.recordingLikelihood);
  
  // 4. Determine how many to store
  let countToStore = 1;
  if (tier === 3) {
    if (context.storyCount === 3) {
      // Story 3 special case: store top 4 (1 shown, 3 locked)
      countToStore = 4;
    } else if (context.storyCount <= 20) {
      countToStore = 3; // Early milestones
    } else if (context.storyCount <= 50) {
      countToStore = 2; // Mid milestones
    } else {
      countToStore = 1; // Late milestones
    }
  } else if (tier === 2) {
    countToStore = 2; // On-demand generates 2
  }
  
  const toStore = filtered.slice(0, countToStore);
  
  // 5. Store prompts
  for (let i = 0; i < toStore.length; i++) {
    const candidate = toStore[i];
    const isLocked = (tier === 3 && context.storyCount === 3 && i > 0); // Lock premium seed
    
    await storePrompt(userId, candidate, tier, isLocked);
  }
}

// ============================================================================
// STORE PROMPT
// ============================================================================

async function storePrompt(
  userId: string,
  prompt: ScoredPrompt,
  tier: number,
  isLocked: boolean = false
): Promise<void> {
  const anchorHash = generateAnchorHash(
    prompt.trigger,
    prompt.anchorEntity,
    prompt.anchorYear
  );
  
  // Determine expiry based on tier
  let expiryDays: number;
  if (isLocked) {
    expiryDays = 0; // NULL (set on unlock)
  } else if (tier === 1) {
    expiryDays = 7;
  } else if (tier === 2) {
    expiryDays = 14;
  } else if (tier === 3) {
    expiryDays = 30;
  } else {
    expiryDays = 7; // Fallback
  }
  
  const expiresAt = isLocked 
    ? null 
    : new Date(Date.now() + expiryDays * 24 * 60 * 60 * 1000);
  
  // Check if prompt already exists (deduplication)
  const existing = await db.active_prompts.findOne({
    where: { userId, anchorHash }
  });
  
  if (existing) {
    console.log(`Duplicate prompt detected for user ${userId}, skipping:`, prompt.prompt);
    return;
  }
  
  // Insert
  await db.active_prompts.create({
    userId,
    promptText: prompt.prompt,
    contextNote: `Based on your ${prompt.anchorYear || 'stories'}`,
    anchorEntity: prompt.anchorEntity,
    anchorYear: prompt.anchorYear,
    anchorHash,
    tier,
    memoryType: prompt.trigger,
    promptScore: prompt.recordingLikelihood,
    scoreReason: prompt.reasoning,
    modelVersion: 'gpt-4o',
    expiresAt,
    isLocked
  });
}

7.3 Decade Fallback Generator
Function: Generate safe fallback when AI fails or inventory is empty


typescript
async function generateDecadeFallback(userId: string): Promise<ScoredPrompt> {
  const user = await db.users.findById(userId);
  const stories = await db.stories.find({ userId });
  
  // Find decades the user has lived through but hasn't recorded from
  const currentYear = new Date().getFullYear();
  const birthYear = user.birthYear;
  const age = currentYear - birthYear;
  
  // All decades they've lived through
  const livedDecades: number[] = [];
  for (let year = birthYear; year <= currentYear; year += 10) {
    const decade = Math.floor(year / 10) * 10;
    if (!livedDecades.includes(decade)) {
      livedDecades.push(decade);
    }
  }
  
  // Decades with existing stories
  const recordedDecades = new Set(
    stories.map(s => Math.floor(s.storyYear / 10) * 10)
  );
  
  // Unrecorded decades
  const unrecordedDecades = livedDecades.filter(d => !recordedDecades.has(d));
  
  // Pick random unrecorded decade
  let decade: number;
  if (unrecordedDecades.length > 0) {
    decade = unrecordedDecades[Math.floor(Math.random() * unrecordedDecades.length)];
  } else {
    // All decades covered - pick random decade they lived through
    decade = livedDecades[Math.floor(Math.random() * livedDecades.length)];
  }
  
  // Generate decade-based prompt
  const prompts = [
    `Tell me about a typical Saturday in the ${decade}s.`,
    `What was your favorite thing about the ${decade}s?`,
    `What do you remember most about ${decade}?`,
    `Tell me a story from the ${decade}s that makes you smile.`,
    `What was happening in your life in ${decade}?`
  ];
  
  const promptText = prompts[Math.floor(Math.random() * prompts.length)];
  
  return {
    prompt: promptText,
    trigger: 'decade_fallback',
    anchorEntity: `${decade}s`,
    anchorYear: decade,
    recordingLikelihood: 60, // Lower score for generic prompts
    reasoning: 'Decade-based fallback prompt'
  };
}

8. EDGE CASES & FALLBACKS
8.1 Empty Inventory Loop Prevention
Scenario: User opens timeline, no active prompts, Tier 2 generates nothing
Solution: Circuit breaker with rate limit + fallback


typescript
async function getNextPromptWithCircuitBreaker(userId: string) {
  // 1. Try to fetch existing prompt
  let prompt = await fetchActivePrompt(userId);
  if (prompt) return prompt;
  
  // 2. Check Tier 2 rate limit (max 1 per 24 hours)
  const user = await db.users.findById(userId);
  const lastAttempt = user.last_tier2_attempt;
  const hoursSinceLast = lastAttempt 
    ? (Date.now() - lastAttempt.getTime()) / (1000 * 60 * 60)
    : 999;
  
  if (hoursSinceLast < 24) {
    // Rate limited - immediate fallback
    return await generateDecadeFallback(userId);
  }
  
  // 3. Try Tier 2 generation
  try {
    await db.users.update(userId, { last_tier2_attempt: new Date() });
    
    const tier2Prompt = await generateTier2Prompt(userId);
    
    if (tier2Prompt) {
      return tier2Prompt;
    } else {
      // Generation returned nothing - fallback
      return await generateDecadeFallback(userId);
    }
  } catch (error) {
    // API error - fallback
    console.error('Tier 2 generation failed:', error);
    return await generateDecadeFallback(userId);
  }
}

8.2 Story 3 Low Quality Scores
Scenario: All 5 Story 3 candidates score < 50 (too low to show)
Solution: Retry with sensory-only focus, then fallback


typescript
async function generateStory3PromptWithRetry(userId: string): Promise<void> {
  // First attempt: standard Story 3 analysis
  const candidates = await generateStory3Candidates(userId);
  const filtered = candidates.filter(c => c.recordingLikelihood >= 50);
  
  if (filtered.length >= 1) {
    // Success - store as normal
    await storeStory3Prompts(userId, filtered);
    return;
  }
  
  // All candidates failed - retry with sensory focus
  console.warn(`Story 3 candidates all scored < 50 for user ${userId}, retrying...`);
  
  const retryPrompt = `
  The previous 5 candidates scored too low. Try again with ONLY sensory detail prompts.
  
  Focus EXCLUSIVELY on:
  - "What did X smell like?"
  - "What color was X?"
  - "What did you hear when X happened?"
  - "Describe the room where X happened"
  
  Generate 3 sensory-focused candidates.
  `;
  
  const retryCandidates = await callOpenAI(retryPrompt);
  const retryFiltered = retryCandidates.filter(c => c.recordingLikelihood >= 50);
  
  if (retryFiltered.length >= 1) {
    // Retry succeeded
    await storeStory3Prompts(userId, retryFiltered);
    return;
  }
  
  // Still failed - use decade fallback as last resort
  console.error(`Story 3 retry also failed for user ${userId}, using fallback`);
  
  const fallback = await generateDecadeFallback(userId);
  await storePrompt(userId, fallback, 3, false);
  
  // Also create 3 generic locked prompts for premium seed
  for (let i = 0; i < 3; i++) {
    const genericFallback = await generateDecadeFallback(userId);
    await storePrompt(userId, genericFallback, 3, true); // Locked
  }
}

8.3 Payment Failure After Story 3
Scenario: User sees Story 3 killer prompt, clicks "See What I Found", but payment fails
Solution: Keep prompts locked, send recovery email


typescript
// Stripe webhook handler
async function handleStripeWebhook(event) {
  if (event.type === 'checkout.session.expired') {
    const userId = event.data.object.client_reference_id;
    
    // Payment failed or abandoned
    // Prompts remain locked
    
    // Send recovery email
    await sendEmail({
      to: user.email,
      subject: "Your Story Analysis is Still Waiting",
      body: `
        Hi ${user.firstName},
        
        I've analyzed your first 3 stories and found 3 specific memories 
        you should record. Your personalized prompts are ready whenever 
        you're ready to continue.
        
        [Complete Your Subscription - $149/year]
        
        Your prompts will be waiting for you.
      `
    });
    
    return { received: true };
  }
}

8.4 User Deletes Story That Generated Prompts
Scenario: User deletes Story 2, which generated prompts about "father's workshop"
Solution: Prompts remain valid (they reference the story, but don't require it)
No action needed - prompts are independent of source story. If user asks "What story is this based on?" and can't find it, that's a rare edge case.
Alternative: Mark prompts as source_story_deleted if you want to handle it:


typescript
async function handleStoryDelete(storyId: string, userId: string) {
  // Delete story
  await db.stories.delete(storyId);
  
  // Optional: Mark related prompts
  await db.active_prompts.updateMany(
    {
      userId,
      sourceStoryIds: { $contains: [storyId] }
    },
    {
      metadata: { sourceStoryDeleted: true }
    }
  );
}

8.5 User Maxes Out do_not_ask Topics
Scenario: User has blocked 20 topics in do_not_ask, AI can't find anything to ask
Solution: Decade fallback + notification


typescript
async function generateWithSafetyFilter(userId: string) {
  const user = await db.users.findById(userId);
  const bannedTopics = user.do_not_ask || [];
  
  if (bannedTopics.length > 15) {
    console.warn(`User ${userId} has ${bannedTopics.length} blocked topics`);
  }
  
  // Generate candidates
  const candidates = await generateCandidates(userId);
  
  // Filter out banned topics
  const safe = candidates.filter(c => {
    const lowerPrompt = c.prompt.toLowerCase();
    return !bannedTopics.some(topic => lowerPrompt.includes(topic.toLowerCase()));
  });
  
  if (safe.length === 0) {
    // All prompts blocked - use decade fallback
    return await generateDecadeFallback(userId);
  }
  
  return safe;
}

9. SAFETY & COMPLIANCE
9.1 do_not_ask Implementation
Purpose: User-controlled topic blocking
Storage:


sql
-- In users table
do_not_ask JSONB DEFAULT '[]'::jsonb

-- Example value:
["divorce", "mother's death", "bankruptcy", "cancer"]
UI Flow:


User clicks "I don't want to be asked about this" on a prompt
  ↓
Modal: "What topic should I avoid?"
  ↓
User types: "my divorce"
  ↓
UPDATE users SET do_not_ask = do_not_ask || '["divorce"]'
WHERE id = $userId
  ↓
Delete any active prompts containing "divorce"
  ↓
Future prompts filtered before insertion
Implementation:


typescript
async function addToDoNotAsk(userId: string, topic: string): Promise<void> {
  // Normalize topic
  const normalized = topic.toLowerCase().trim();
  
  // Add to user's do_not_ask list
  await db.query(`
    UPDATE users
    SET do_not_ask = 
      CASE 
        WHEN do_not_ask IS NULL THEN $2::jsonb
        ELSE do_not_ask || $2::jsonb
      END
    WHERE id = $1
  `, [userId, JSON.stringify([normalized])]);
  
  // Delete any active prompts containing this topic
  const prompts = await db.active_prompts.find({ userId });
  
  for (const prompt of prompts) {
    if (prompt.prompt_text.toLowerCase().includes(normalized)) {
      await db.active_prompts.delete(prompt.id);
      console.log(`Removed prompt containing banned topic "${topic}":`, prompt.prompt_text);
    }
  }
}

async function filterBannedTopics(
  userId: string, 
  candidates: ScoredPrompt[]
): Promise<ScoredPrompt[]> {
  const user = await db.users.findById(userId);
  const bannedTopics = user.do_not_ask || [];
  
  if (bannedTopics.length === 0) {
    return candidates;
  }
  
  return candidates.filter(c => {
    const lowerPrompt = c.prompt.toLowerCase();
    const containsBanned = bannedTopics.some(topic => 
      lowerPrompt.includes(topic.toLowerCase())
    );
    return !containsBanned;
  });
}

9.2 Content Safety Classifier
Purpose: Block sensitive topics before insertion
Blocked Topics:


typescript
const SENSITIVE_TOPICS = {
  trauma: [
    'abuse', 'assault', 'molest', 'rape', 'violence', 
    'beaten', 'attacked', 'traumatized'
  ],
  death: [
    'died', 'death', 'funeral', 'suicide', 'killed',
    'passed away', 'terminal', 'fatal'
  ],
  addiction: [
    'alcoholic', 'addict', 'overdose', 'rehab', 
    'drinking problem', 'substance abuse'
  ],
  financial: [
    'bankruptcy', 'foreclosure', 'eviction', 'homeless',
    'broke', 'debt', 'financial ruin'
  ],
  infidelity: [
    'affair', 'cheated', 'infidelity', 'adultery',
    'unfaithful', 'mistress', 'lover'
  ],
  medical: [
    'cancer', 'diagnosis', 'surgery', 'hospital',
    'disease', 'illness', 'treatment'
  ]
};
Classification Function:


typescript
function classifyPromptSafety(promptText: string): {
  safe: boolean;
  category?: string;
  matched?: string;
} {
  const lowerPrompt = promptText.toLowerCase();
  
  for (const [category, keywords] of Object.entries(SENSITIVE_TOPICS)) {
    for (const keyword of keywords) {
      if (lowerPrompt.includes(keyword)) {
        return {
          safe: false,
          category,
          matched: keyword
        };
      }
    }
  }
  
  return { safe: true };
}
Application:


typescript
async function storePromptWithSafety(
  userId: string,
  prompt: ScoredPrompt,
  tier: number
): Promise<void> {
  // Check safety
  const safety = classifyPromptSafety(prompt.prompt);
  
  if (!safety.safe) {
    console.warn(
      `Blocked unsafe prompt for user ${userId}:`,
      `Category: ${safety.category}, Matched: ${safety.matched}`
    );
    return; // Don't store
  }
  
  // Check user's do_not_ask
  const user = await db.users.findById(userId);
  const bannedTopics = user.do_not_ask || [];
  
  for (const topic of bannedTopics) {
    if (prompt.prompt.toLowerCase().includes(topic.toLowerCase())) {
      console.warn(`Blocked prompt matching do_not_ask topic "${topic}"`);
      return; // Don't store
    }
  }
  
  // Safe - proceed with storage
  await storePrompt(userId, prompt, tier);
}
Exception: User initiates the topic


typescript
// If user's story mentions "cancer", it's OK to ask follow-ups about cancer
// The classifier only blocks UNSOLICITED sensitive prompts

function shouldAllowSensitiveTopic(
  prompt: string,
  userStories: Story[]
): boolean {
  const safety = classifyPromptSafety(prompt);
  
  if (safety.safe) return true;
  
  // Check if user already discussed this topic
  const userMentionedIt = userStories.some(story => 
    story.transcript.toLowerCase().includes(safety.matched)
  );
  
  if (userMentionedIt) {
    console.log(
      `Allowing sensitive prompt because user initiated topic: ${safety.matched}`
    );
    return true;
  }
  
  return false;
}

9.3 Recent Death Detection
Purpose: Never ask about deaths within 1 year
Implementation:


typescript
function detectRecentDeath(transcript: string, storyYear: number): boolean {
  const deathIndicators = [
    /died/i, /passed away/i, /funeral/i, /buried/i,
    /lost (my|our) (mom|dad|mother|father|wife|husband|son|daughter)/i
  ];
  
  const currentYear = new Date().getFullYear();
  const yearsSinceDeath = currentYear - storyYear;
  
  if (yearsSinceDeath < 1) {
    // Story is from this year - check for death mentions
    return deathIndicators.some(pattern => pattern.test(transcript));
  }
  
  return false;
}

// In generateTier1Template:
if (detectRecentDeath(transcript, storyYear)) {
  console.log('Skipping Tier 1 prompt generation - recent death detected');
  return null; // Don't generate any prompt
}

10. METRICS & SUCCESS CRITERIA
10.1 Primary KPIs
Prompt → Recording Conversion Rate


sql
-- Overall conversion by tier
SELECT 
  tier,
  COUNT(CASE WHEN outcome = 'used' THEN 1 END)::FLOAT / COUNT(*) * 100 AS conversion_rate,
  AVG(shown_count) AS avg_shows_before_outcome
FROM prompt_history
GROUP BY tier
ORDER BY tier;

-- Targets:
-- Tier 1: ≥ 50%
-- Tier 2: ≥ 70%
-- Tier 3: ≥ 80%
Free Tier Funnel Conversion


sql
-- Story 1 → Story 2 → Story 3 → Payment
SELECT 
  COUNT(CASE WHEN free_stories_used >= 1 THEN 1 END) AS reached_story_1,
  COUNT(CASE WHEN free_stories_used >= 2 THEN 1 END) AS reached_story_2,
  COUNT(CASE WHEN free_stories_used >= 3 THEN 1 END) AS reached_story_3,
  COUNT(CASE WHEN subscription_status = 'active' THEN 1 END) AS converted_to_paid,
  
  COUNT(CASE WHEN free_stories_used >= 2 THEN 1 END)::FLOAT / 
    NULLIF(COUNT(CASE WHEN free_stories_used >= 1 THEN 1 END), 0) * 100 AS story1_to_2_rate,
  
  COUNT(CASE WHEN free_stories_used >= 3 THEN 1 END)::FLOAT / 
    NULLIF(COUNT(CASE WHEN free_stories_used >= 2 THEN 1 END), 0) * 100 AS story2_to_3_rate,
  
  COUNT(CASE WHEN subscription_status = 'active' THEN 1 END)::FLOAT / 
    NULLIF(COUNT(CASE WHEN free_stories_used >= 3 THEN 1 END), 0) * 100 AS story3_to_paid_rate
FROM users
WHERE created_at >= '2025-01-01';

-- Targets:
-- Story 1 → 2: ≥ 65%
-- Story 2 → 3: ≥ 55%
-- Story 3 → Paid: ≥ 45%

10.2 Secondary Metrics
Stories Per User Per Month


sql
SELECT 
  DATE_TRUNC('month', created_at) AS month,
  COUNT(*)::FLOAT / COUNT(DISTINCT user_id) AS avg_stories_per_user
FROM stories
WHERE created_at >= NOW() - INTERVAL '6 months'
GROUP BY month
ORDER BY month;

-- Target: ≥ 3 stories/user/month for active users
Days Between Recordings


sql
WITH story_gaps AS (
  SELECT 
    user_id,
    created_at,
    LAG(created_at) OVER (PARTITION BY user_id ORDER BY created_at) AS prev_created_at,
    EXTRACT(EPOCH FROM (created_at - LAG(created_at) OVER (PARTITION BY user_id ORDER BY created_at))) / 86400 AS days_since_last
  FROM stories
)
SELECT 
  AVG(days_since_last) AS avg_days_between_stories,
  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY days_since_last) AS median_days
FROM story_gaps
WHERE days_since_last IS NOT NULL;

-- Target: ≤ 10 days average
Prompt Skip Rate


sql
SELECT 
  tier,
  memory_type,
  COUNT(*) AS total_skipped,
  AVG(shown_count) AS avg_shows_before_skip
FROM prompt_history
WHERE outcome = 'skipped'
GROUP BY tier, memory_type
ORDER BY total_skipped DESC;

-- Target: < 2 skips before use
Active Prompt Inventory Health


sql
SELECT 
  user_id,
  COUNT(*) AS active_prompts,
  AVG(prompt_score) AS avg_score,
  MAX(expires_at) AS furthest_expiry
FROM active_prompts
WHERE expires_at > NOW()
  AND is_locked = false
GROUP BY user_id
HAVING COUNT(*) > 5;

-- Target: 1-5 active prompts per user (not >5)

10.3 Quality Metrics
Prompt Score Correlation with Conversion


sql
-- Does higher prompt_score actually lead to more "used" outcomes?
SELECT 
  CASE 
    WHEN prompt_score >= 80 THEN '80-100'
    WHEN prompt_score >= 60 THEN '60-79'
    WHEN prompt_score >= 40 THEN '40-59'
    ELSE '0-39'
  END AS score_bucket,
  COUNT(CASE WHEN outcome = 'used' THEN 1 END)::FLOAT / COUNT(*) * 100 AS conversion_rate
FROM prompt_history
WHERE tier IN (2, 3)  -- Only AI-generated prompts
GROUP BY score_bucket
ORDER BY score_bucket DESC;

-- Expected: Higher scores → higher conversion
-- If not, scorer needs refinement
Tier Effectiveness


sql
SELECT 
  tier,
  COUNT(*) AS total_generated,
  COUNT(CASE WHEN outcome = 'used' THEN 1 END) AS used,
  COUNT(CASE WHEN outcome = 'skipped' THEN 1 END) AS skipped,
  COUNT(CASE WHEN outcome = 'expired' THEN 1 END) AS expired,
  AVG(prompt_score) AS avg_score
FROM prompt_history
GROUP BY tier
ORDER BY tier;

-- Insights:
-- High expiry rate → increase expiry window
-- High skip rate → improve prompt quality
-- Low usage → wrong prompts being generated
Memory Type Performance


sql
SELECT 
  memory_type,
  COUNT(*) AS total,
  COUNT(CASE WHEN outcome = 'used' THEN 1 END)::FLOAT / COUNT(*) * 100 AS conversion_rate,
  AVG(prompt_score) AS avg_score
FROM prompt_history
WHERE tier = 1  -- Templates only
GROUP BY memory_type
ORDER BY conversion_rate DESC;

-- Identifies which template types work best
-- Retire low-performing templates

10.4 Business Impact Metrics
Incremental Revenue from AI Prompts


sql
-- Compare conversion rates: users who saw AI prompts vs control
-- (Requires A/B test setup)

SELECT 
  CASE WHEN saw_tier3_prompt THEN 'With AI' ELSE 'Control' END AS cohort,
  COUNT(*) AS users,
  COUNT(CASE WHEN subscription_status = 'active' THEN 1 END) AS conversions,
  COUNT(CASE WHEN subscription_status = 'active' THEN 1 END)::FLOAT / COUNT(*) * 100 AS conversion_rate
FROM (
  SELECT 
    u.id,
    u.subscription_status,
    EXISTS(
      SELECT 1 FROM prompt_history ph 
      WHERE ph.user_id = u.id AND ph.tier = 3 AND ph.outcome = 'used'
    ) AS saw_tier3_prompt
  FROM users u
  WHERE u.created_at >= '2025-01-01'
) cohorts
GROUP BY cohort;

-- Calculate lift:
-- (With AI conversion rate - Control conversion rate) / Control conversion rate * 100
Cost Per Conversion


sql
-- Assume $1,757 annual AI cost for 1,000 paid users
SELECT 
  COUNT(CASE WHEN subscription_status = 'active' THEN 1 END) AS paid_users,
  1757.0 / NULLIF(COUNT(CASE WHEN subscription_status = 'active' THEN 1 END), 0) AS cost_per_paid_user
FROM users;

-- Target: < $2.00 per paid user

10.5 Dashboard Queries
Weekly Health Check


sql
-- Run every Monday
SELECT 
  'Prompt Conversion' AS metric,
  (SELECT AVG(CASE WHEN outcome = 'used' THEN 1.0 ELSE 0.0 END) * 100 
   FROM prompt_history 
   WHERE created_at >= NOW() - INTERVAL '7 days') AS value,
  70.0 AS target
  
UNION ALL

SELECT 
  'Free Tier Conversion',
  (SELECT COUNT(CASE WHEN subscription_status = 'active' THEN 1 END)::FLOAT / 
          NULLIF(COUNT(CASE WHEN free_stories_used >= 3 THEN 1 END), 0) * 100
   FROM users 
   WHERE created_at >= NOW() - INTERVAL '7 days'),
  45.0
  
UNION ALL

SELECT 
  'Stories Per User',
  (SELECT COUNT(*)::FLOAT / NULLIF(COUNT(DISTINCT user_id), 0)
   FROM stories 
   WHERE created_at >= NOW() - INTERVAL '30 days'),
  3.0
  
UNION ALL

SELECT 
  'Active Prompts',
  (SELECT AVG(cnt) FROM (
    SELECT COUNT(*) AS cnt FROM active_prompts 
    WHERE expires_at > NOW() 
    GROUP BY user_id
  ) x),
  3.0;

11. COST MODEL & BUDGET
11.1 Free Tier Costs
Assumptions:
	•	10,000 signups/year
	•	80% record Story 1 = 8,000 users
	•	65% record Story 2 = 5,200 users
	•	55% record Story 3 = 2,860 users
OpenAI API Costs:


Story 1 Analysis:
  - 8,000 users × $0.004 (single story, GPT-4o) = $32.00

Story 2 Analysis:
  - 5,200 users × $0.006 (two stories, GPT-4o) = $31.20

Story 3 Analysis:
  - 2,860 users × $0.008 (three stories, GPT-4o) = $22.88

TOTAL FREE TIER: $86.08/year

11.2 Paid Tier Costs
Assumptions:
	•	1,287 paid users (45% conversion from Story 3)
	•	Average 30 stories/user/year
Tier 1 (Templates):


Cost: $0 (no API calls)
Tier 2 (On-Demand):


Frequency: 2-3x per month per user = ~30 calls/user/year
Cost per call: $0.05 (GPT-4o, 5 stories analyzed, 5 candidates generated)

1,287 users × 30 calls × $0.05 = $1,930.50/year
Tier 3 (Milestones):


Milestones per user (average):
- Story 4: 1,287 users × $0.01 = $12.87
- Story 7: 1,100 users × $0.015 = $16.50
- Story 10: 950 users × $0.02 = $19.00
- Story 15: 800 users × $0.025 = $20.00
- Story 20: 650 users × $0.03 = $19.50
- Story 30: 400 users × $0.045 = $18.00
- Story 50: 200 users × $0.075 = $15.00
- Story 100: 80 users × $0.13 = $10.40

TOTAL TIER 3: $131.27/year
Total Paid Tier: $1,930.50 + $131.27 = $2,061.77/year

11.3 Total Annual Budget


Free Tier:      $86.08
Paid Tier:      $2,061.77
─────────────────────────
TOTAL:          $2,147.85/year

Revenue (1,287 paid users × $149):  $191,763
AI Cost as % of Revenue:            1.12%
Cost Per Paid User:                 $1.67/year

11.4 Scaling Projections
At 10,000 Paid Users:


Free Tier (100k signups):   $860
Paid Tier (10k users):      $20,618
────────────────────────────
TOTAL:                      $21,478/year

Revenue (10k × $149):       $1,490,000
AI Cost as % of Revenue:    1.44%
Cost Per Paid User:         $2.15/year
At 100,000 Paid Users:


Free Tier (1M signups):     $8,600
Paid Tier (100k users):     $206,180
────────────────────────────
TOTAL:                      $214,780/year

Revenue (100k × $149):      $14,900,000
AI Cost as % of Revenue:    1.44%
Cost Per Paid User:         $2.15/year
Cost scales linearly with users, never exceeds 1.5% of revenue.

11.5 Cost Optimization Opportunities
If budget becomes a concern:
	1	Reduce Tier 2 Frequency
	◦	Change from 30 calls/year to 20 calls/year
	◦	Savings: ~$645/year at 1,287 users
	2	Use GPT-4o-mini for Tier 2
	◦	Cost drops from $0.05 to $0.01 per call
	◦	Savings: ~$1,544/year at 1,287 users
	◦	Tradeoff: Lower quality prompts
	3	Reduce Tier 3 Milestones
	◦	Remove Story 4 and 7 milestones
	◦	Savings: ~$29/year at 1,287 users
	◦	Tradeoff: Less early magic
	4	Increase Tier 2 Rate Limit
	◦	Change from 24 hours to 48 hours
	◦	Reduces calls by ~30%
	◦	Savings: ~$579/year at 1,287 users
Recommendation: Don't optimize yet. Current cost (1.12% of revenue) is negligible. Wait until 10K+ users before considering optimizations.

12. IMPLEMENTATION CHECKLIST
Phase 1: Foundation (Week 1)
Database:
	•	Add active_prompts table
	•	Add prompt_history table
	•	Add columns to users table (free_stories_used, subscription_status, etc)
	•	Add source_prompt_id to stories table
	•	Create indexes
	•	Create cleanup function
Tier 1 Templates:
	•	Build entity extraction (people, places, objects, emotions)
	•	Build template library
	•	Build template matching function
	•	Build anchor hash generator
	•	Test with 10 real stories
API Endpoints:
	•	Update POST /api/stories to generate Tier 1
	•	Create GET /api/prompts/next
	•	Create POST /api/prompts/skip
	•	Test all endpoints
Deliverable: Tier 1 templates working end-to-end

Phase 2: Free Tier Magic (Week 2)
Story 1 Analysis:
	•	Write OpenAI prompt template for Story 1
	•	Build generate-and-filter function
	•	Build quality threshold (score ≥ 50)
	•	Build retry logic (sensory-only fallback)
	•	Test with 20 real Story 1 examples
Story 2 Analysis:
	•	Write OpenAI prompt template for Story 2
	•	Build connection detection logic
	•	Test with 20 real Story 1+2 pairs
Story 3 Analysis:
	•	Write OpenAI prompt template for Story 3
	•	Build premium seed storage (is_locked flag)
	•	Build paywall card UI
	•	Test conversion flow end-to-end
Deliverable: Free tier (Stories 1-3) working with AI prompts

Phase 3: Payment Integration (Week 2)
Stripe Webhook:
	•	Create POST /api/webhooks/stripe
	•	Handle checkout.session.completed
	•	Unlock premium seed prompts on payment
	•	Send welcome email
	•	Test with Stripe test mode
Grace Period:
	•	Implement 7-day read-only grace
	•	Schedule emails (Day 1, 3, 5)
	•	Lock account on Day 7
	•	Test full grace period flow
Deliverable: Payment → unlock flow working

Phase 4: Paid Tier (Week 3)
Tier 2 On-Demand:
	•	Write OpenAI prompt template
	•	Build rate limiter (24 hours)
	•	Build circuit breaker with decade fallback
	•	Test empty inventory scenario
Tier 3 Milestones:
	•	Write Discovery phase prompt (Stories 4-20)
	•	Write Pattern phase prompt (Stories 30+)
	•	Build milestone trigger logic (4,7,10,15,20,30,50,100)
	•	Build tapering logic (3 prompts early, 1 late)
	•	Test all milestones
Deliverable: Paid tier milestones working

Phase 5: Safety & Quality (Week 3-4)
Safety Systems:
	•	Build content safety classifier
	•	Build do_not_ask UI and backend
	•	Build recent death detection
	•	Test all safety filters
Quality Systems:
	•	Build prompt score correlation tracking
	•	Build template performance analytics
	•	Create weekly health check dashboard
	•	Document all metrics queries
Deliverable: Safety and quality systems operational

Phase 6: Polish & Launch (Week 4)
UI/UX:
	•	"Next Story" card component
	•	"Record This Story" button
	•	"Skip" button with rotation
	•	Paywall card design
	•	Premium unlock animation
	•	Mobile responsive check
Testing:
	•	End-to-end user journey (free → paid)
	•	Load testing (1000 concurrent users)
	•	OpenAI error handling
	•	Database cleanup job
	•	Cost tracking dashboard
Launch:
	•	Deploy to production
	•	Monitor error logs
	•	Track conversion metrics
	•	A/B test variations
Deliverable: System in production with monitoring

FINAL NOTES
This Document Contains:
✅ Complete product context and business goals ✅ Full system architecture with three tiers ✅ Detailed user flows for free and paid tiers ✅ Complete database schema with DDL ✅ All API endpoint specifications ✅ Exact OpenAI prompt templates for all scenarios ✅ Business logic and algorithms (extraction, scoring, filtering) ✅ Edge case handling and fallback strategies ✅ Safety and compliance systems ✅ Metrics, success criteria, and dashboard queries ✅ Cost model with scaling projections ✅ Implementation checklist with phases
What's NOT in This Document:
❌ Frontend React code (separate spec) ❌ Deployment/infrastructure (separate DevOps doc) ❌ Email templates (separate marketing doc)
How to Use This Document:
	1	Read Section 1 (Product Context) to understand the "why"
	2	Read Section 2 (Architecture) to understand the "how"
	3	Read Sections 3-9 to implement features
	4	Read Section 10 to track success
	5	Read Section 11 to manage costs
	6	Read Section 12 to plan work
Questions to Ask Before Building:
	•	Do we have OpenAI API key with sufficient credits?
	•	Is Supabase database provisioned and accessible?
	•	Is Stripe account set up with webhook endpoints?
	•	Do we have test users for free tier validation?
	•	Are analytics/monitoring tools ready (Posthog, Sentry)?

This document is ready for handoff to engineering.
Estimated build time: 3-4 weeks for one senior full-stack developer Estimated cost to build: $20-30K (contractor rates) Estimated annual AI cost: $2,148 (at 1,287 paid users) Expected ROI: 28x (if 5% conversion lift achieved)
Ship i
